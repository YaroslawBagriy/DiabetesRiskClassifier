{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aeacc44",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe95986b-938e-4228-be82-5f5773bf3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e511eaa0",
   "metadata": {},
   "source": [
    "# Load\n",
    "This is where the prepared data is loaded in for use in training and testing of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1281416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned and preprocessed data\n",
    "X_train = pd.read_csv(\"data/X_train.csv\", index_col=0).astype(float)\n",
    "y_train = pd.read_csv(\"data/y_train.csv\", index_col=0).astype(int)\n",
    "y_train = pd.Series(y_train.values.ravel())\n",
    "y_train.index = X_train.index\n",
    "y_train_binary = pd.read_csv(\"data/y_train_binary.csv\", index_col=0).astype(int)\n",
    "y_train_binary = pd.Series(y_train_binary.values.ravel())\n",
    "y_train_binary.index = X_train.index\n",
    "X_test = pd.read_csv(\"data/X_test.csv\", index_col=0).astype(float)\n",
    "y_test = pd.read_csv(\"data/y_test.csv\", index_col=0).astype(int)\n",
    "y_test = pd.Series(y_test.values.ravel())\n",
    "y_test.index = X_test.index\n",
    "y_test_binary = pd.read_csv(\"data/y_test_binary.csv\", index_col=0).astype(int)\n",
    "y_test_binary = pd.Series(y_test_binary.values.ravel())\n",
    "y_test_binary.index = X_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0192a894",
   "metadata": {},
   "source": [
    "# Two Stage Decision Tree Model\n",
    "This section is where the two stage decision tree model is trained and tested. First class 1 and class 2 are merged into a single class and a decision tree model is trained to predict class 0 against the combined class 1 and 2. A second model is then trained to predict class 1 against class 2. The output of these two models is then combined to create a prediction of all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3391ce3c-1477-45a5-b1c6-a0deca15dd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First Stage Classification Report (class 0 vs class 1+2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.62      0.74     38012\n",
      "           1       0.30      0.77      0.43      7945\n",
      "\n",
      "    accuracy                           0.64     45957\n",
      "   macro avg       0.61      0.69      0.58     45957\n",
      "weighted avg       0.82      0.64      0.69     45957\n",
      "\n",
      "\n",
      "Second Stage Classification Report (class 1 vs class 2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.13      0.35      0.19       619\n",
      "           2       0.91      0.75      0.82      5517\n",
      "\n",
      "    accuracy                           0.71      6136\n",
      "   macro avg       0.52      0.55      0.51      6136\n",
      "weighted avg       0.83      0.71      0.76      6136\n",
      "\n",
      "\n",
      "Final SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.62      0.74     38012\n",
      "           1       0.01      0.23      0.03       926\n",
      "           2       0.91      0.59      0.71      7019\n",
      "\n",
      "    accuracy                           0.60     45957\n",
      "   macro avg       0.62      0.48      0.49     45957\n",
      "weighted avg       0.91      0.60      0.72     45957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model parameters\n",
    "desired_max_depth = 5\n",
    "\n",
    "# Train first Model: 0 vs (1+2)\n",
    "first_stage_tree = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=desired_max_depth,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "first_stage_tree.fit(X_train, y_train_binary)\n",
    "\n",
    "# Predict first stage\n",
    "y_pred_binary = first_stage_tree.predict(X_test)\n",
    "\n",
    "print(\"\\nFirst Stage Classification Report (class 0 vs class 1+2):\")\n",
    "print(classification_report(y_test_binary, y_pred_binary))\n",
    "\n",
    "# Stage 2: 1 vs 2\n",
    "# Get original test labels with 0/1/2\n",
    "y_test_full = y_test.loc[y_test_binary.index]\n",
    "\n",
    "# Find samples predicted as diabetic\n",
    "indices_pred_diabetes = np.where(y_pred_binary == 1)[0]\n",
    "X_test_diabetes = X_test.iloc[indices_pred_diabetes]\n",
    "y_test_diabetes = y_test_full.iloc[indices_pred_diabetes]\n",
    "\n",
    "# Keep only class 1 and 2\n",
    "# Pull records where y_test_diabetes is class 1 or class 2, along with their indexes\n",
    "test_diabetes = y_test_diabetes.loc[(y_test_diabetes == 1) | (y_test_diabetes == 2)].index\n",
    "X_test_diabetes = X_test_diabetes.loc[test_diabetes]\n",
    "y_test_diabetes = y_test_diabetes.loc[test_diabetes]\n",
    "\n",
    "# Prepare second-stage training data\n",
    "# Get the indexes where y_train_binary == 1\n",
    "diabetes_indexes = y_train_binary.loc[y_train_binary == 1].index\n",
    "\n",
    "# Use these indexes to select records from X_train_diabetes and y_train_diabetes\n",
    "X_train_diabetes = X_train.loc[diabetes_indexes]\n",
    "y_train_diabetes = y_train.loc[diabetes_indexes]\n",
    "\n",
    "second_stage_tree = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=desired_max_depth,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "second_stage_tree.fit(X_train_diabetes, y_train_diabetes)\n",
    "\n",
    "# Predict second stage\n",
    "y_pred_second_stage = second_stage_tree.predict(X_test_diabetes)\n",
    "\n",
    "print(\"\\nSecond Stage Classification Report (class 1 vs class 2):\")\n",
    "print(classification_report(y_test_diabetes, y_pred_second_stage))\n",
    "\n",
    "# Reconstruct final prediction array\n",
    "y_pred_final = y_pred_binary.copy()\n",
    "pred_diabetes_indices = np.where(y_pred_binary == 1)[0]\n",
    "\n",
    "# Reindex and assign\n",
    "y_test_full_diabetes = y_test_full.iloc[pred_diabetes_indices]\n",
    "valid_indices = pred_diabetes_indices[(y_test_full_diabetes == 1) | (y_test_full_diabetes == 2)]\n",
    "\n",
    "for i, idx in enumerate(valid_indices):\n",
    "    y_pred_final[idx] = y_pred_second_stage[i]\n",
    "\n",
    "print(\"\\nFinal SVM Classification Report:\")\n",
    "print(classification_report(y_test_full, y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f53674-6cca-42c0-985b-07b1759e4c4f",
   "metadata": {},
   "source": [
    "# Export\n",
    "This section is where the final predictions of the two stage decision tree model are exported for use by the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f68eec-8bb8-4e4f-8c78-2c0d9d4aa1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "# --------------------------------------------\n",
    "import os\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "np.save(\"results/y_pred_dt.npy\", y_pred_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
