{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe95986b-938e-4228-be82-5f5773bf3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46799ea9-fc6d-4ae4-80b1-48995e0e3fee",
   "metadata": {},
   "source": [
    "# Decision Tree Modeling\n",
    "\n",
    "In this step we'll load the cleaned data set and then perform the modeling steps.\n",
    "\n",
    "Diabetes_012 class types:\n",
    "- 0 is for no diabetes or only during pregnancy\n",
    "- 1 is for prediabetes\n",
    "- 2 is for diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12401c42-5662-408f-b969-45c276e8c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data from eda step\n",
    "file_path = \"../data/cleaned_diabetes_health_indicators_dataset.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa524b04-928c-4212-9509-b6f83418cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(\"Diabetes_012\", axis=1)\n",
    "y = df[\"Diabetes_012\"]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "538ef001-16b4-46b9-a5b7-4b08eae51879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.98      0.91     38116\n",
      "         1.0       0.00      0.00      0.00       906\n",
      "         2.0       0.55      0.13      0.21      6935\n",
      "\n",
      "    accuracy                           0.83     45957\n",
      "   macro avg       0.47      0.37      0.37     45957\n",
      "weighted avg       0.78      0.83      0.79     45957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaroslawbagriy/Dev/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yaroslawbagriy/Dev/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yaroslawbagriy/Dev/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train the decision tree using entropy as the criterion and a max depth of 5\n",
    "clf_entropy_5 = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=42)\n",
    "clf_entropy_5.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the results\n",
    "y_entropy_5 = clf_entropy_5.predict(X_test)\n",
    "print(classification_report(y_test, y_entropy_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "032c4b7b-f7b6-437f-8721-f2f76f923d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.99      0.91     38116\n",
      "         1.0       0.00      0.00      0.00       906\n",
      "         2.0       0.57      0.12      0.19      6935\n",
      "\n",
      "    accuracy                           0.83     45957\n",
      "   macro avg       0.47      0.37      0.37     45957\n",
      "weighted avg       0.78      0.83      0.78     45957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaroslawbagriy/Dev/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yaroslawbagriy/Dev/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yaroslawbagriy/Dev/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train the decision tree using entropy as the criterion and a max depth of 5\n",
    "clf_gini_5 = DecisionTreeClassifier(criterion='gini', max_depth=5, random_state=42)\n",
    "clf_gini_5.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the results\n",
    "y_gini_5 = clf_gini_5.predict(X_test)\n",
    "print(classification_report(y_test, y_gini_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f28073-7f8f-4b7d-ba10-d06b0bb077ef",
   "metadata": {},
   "source": [
    "We can see that using the decision tree with criterion set to entropy and gini with a max tree depth of 5 will be unable to predict class 1 (pre-prediabetes). Let's try the following:\n",
    "1. No max depth set\n",
    "2. Max depth of 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c4a5a78-c0d7-4eaa-aae1-f618413f85c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85     38116\n",
      "         1.0       0.03      0.04      0.04       906\n",
      "         2.0       0.29      0.31      0.30      6935\n",
      "\n",
      "    accuracy                           0.75     45957\n",
      "   macro avg       0.39      0.40      0.40     45957\n",
      "weighted avg       0.76      0.75      0.75     45957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the decision tree using entropy as the criterion and no max depth\n",
    "clf_entropy_5 = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "clf_entropy_5.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the results\n",
    "y_entropy_5 = clf_entropy_5.predict(X_test)\n",
    "print(classification_report(y_test, y_entropy_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bbec8db-1039-40b1-af24-aa3635b1bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.83      0.85     38116\n",
      "         1.0       0.02      0.02      0.02       906\n",
      "         2.0       0.28      0.32      0.30      6935\n",
      "\n",
      "    accuracy                           0.74     45957\n",
      "   macro avg       0.39      0.39      0.39     45957\n",
      "weighted avg       0.76      0.74      0.75     45957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the decision tree using entropy as the criterion and no max depth\n",
    "clf_gini_5 = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "clf_gini_5.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the results\n",
    "y_gini_5 = clf_gini_5.predict(X_test)\n",
    "print(classification_report(y_test, y_gini_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f511d566-89a6-40e6-b5c7-32b9d03122e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.84      0.85     38116\n",
      "         1.0       0.03      0.04      0.04       906\n",
      "         2.0       0.29      0.31      0.30      6935\n",
      "\n",
      "    accuracy                           0.75     45957\n",
      "   macro avg       0.39      0.40      0.40     45957\n",
      "weighted avg       0.76      0.75      0.75     45957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the decision tree using entropy as the criterion and max depth 50\n",
    "clf_entropy_5 = DecisionTreeClassifier(criterion='entropy', max_depth=50, random_state=42)\n",
    "clf_entropy_5.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the results\n",
    "y_entropy_5 = clf_entropy_5.predict(X_test)\n",
    "print(classification_report(y_test, y_entropy_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "045ebb94-3110-4bcc-b777-fe364a69bd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.83      0.85     38116\n",
      "         1.0       0.02      0.02      0.02       906\n",
      "         2.0       0.28      0.32      0.30      6935\n",
      "\n",
      "    accuracy                           0.74     45957\n",
      "   macro avg       0.39      0.39      0.39     45957\n",
      "weighted avg       0.76      0.74      0.75     45957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the decision tree using entropy as the criterion and max depth 50\n",
    "clf_gini_5 = DecisionTreeClassifier(criterion='gini', max_depth=50, random_state=42)\n",
    "clf_gini_5.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the results\n",
    "y_gini_5 = clf_gini_5.predict(X_test)\n",
    "print(classification_report(y_test, y_gini_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0a521-d68e-46ae-9f83-ddfcafb7f18d",
   "metadata": {},
   "source": [
    "Due to how imbalanced this data set is the precision, recall, and f1-score is very low for class 1 and class 2. We can try to improve these results by trying the following:\n",
    "1. Set class_weight=\"balanced\". This will help give more weight to the imbalanced classes.\n",
    "2. Try controling the complexity of the decision tree by providing a maximum depth.\n",
    "3. Set min_samples_leaf, which will help the Decision Tree not overfit to the majority class (class 0, no diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "200066a2-022b-49ad-b2f2-1e89cd7486ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.65      0.75     38116\n",
      "         1.0       0.03      0.17      0.05       906\n",
      "         2.0       0.27      0.52      0.36      6935\n",
      "\n",
      "    accuracy                           0.62     45957\n",
      "   macro avg       0.40      0.45      0.39     45957\n",
      "weighted avg       0.79      0.62      0.68     45957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the decision tree using entropy as the criterion and max depth 50\n",
    "clf_entropy_5 = DecisionTreeClassifier(criterion='entropy',  class_weight='balanced', min_samples_leaf=8, max_depth=50, random_state=42)\n",
    "clf_entropy_5.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the results\n",
    "y_entropy_5 = clf_entropy_5.predict(X_test)\n",
    "print(classification_report(y_test, y_entropy_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f6ce298-6809-4989-979c-4d76bb2e11c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.59      0.72     38116\n",
      "         1.0       0.03      0.31      0.06       906\n",
      "         2.0       0.30      0.54      0.38      6935\n",
      "\n",
      "    accuracy                           0.57     45957\n",
      "   macro avg       0.42      0.48      0.39     45957\n",
      "weighted avg       0.82      0.57      0.66     45957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the decision tree using entropy as the criterion and max depth 50\n",
    "clf_gini_5 = DecisionTreeClassifier(criterion='gini',  class_weight='balanced', min_samples_leaf=8, max_depth=15, random_state=42)\n",
    "clf_gini_5.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the results\n",
    "y_gini_5 = clf_gini_5.predict(X_test)\n",
    "print(classification_report(y_test, y_gini_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391ce3c-1477-45a5-b1c6-a0deca15dd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
