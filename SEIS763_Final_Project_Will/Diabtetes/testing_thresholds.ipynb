{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c81dd5d-83d6-49e9-a887-d281ba144e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "0     1.0       1.0        1.0  40.0     1.0     0.0                   0.0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  ...  AnyHealthcare  NoDocbcCost  GenHlth  \\\n",
       "0           0.0     0.0      1.0  ...            1.0          0.0      5.0   \n",
       "\n",
       "   MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  Income  \n",
       "0      18.0      15.0       1.0  0.0  9.0        4.0     3.0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, classification_report, roc_auc_score, log_loss\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "original_df = pd.read_csv('Data/diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "\n",
    "y = original_df.Diabetes_012\n",
    "X = original_df.drop('Diabetes_012', axis=1)\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46676e0c-4582-4faa-b2d7-a7123580e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Predictors\n",
    "numerical_cols = ['BMI', 'MentHlth', 'PhysHlth', 'Age']\n",
    "# numerical_cols = list(dict.fromkeys(numerical_cols))  # Remove duplicates just in case\n",
    "\n",
    "# Categorical Predictors\n",
    "categorical_cols = [\n",
    "    'HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "    'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "    'NoDocbcCost', 'GenHlth', 'DiffWalk', 'Sex', 'Education', 'Income'\n",
    "]\n",
    "\n",
    "# One-hot encode categorical features and drop the first category of each\n",
    "# Feature Engineering - Turns categorical data into a numerical format that a model can understand\n",
    "X_cat = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Extract the numerical features\n",
    "X_num = X[numerical_cols]\n",
    "\n",
    "# Concatenate numerical and encoded categorical features\n",
    "X = pd.concat([X_num, X_cat], axis=1)\n",
    "\n",
    "# Remove any duplicated columns that may result from concat\n",
    "X = X.loc[:, ~X.columns.duplicated()]\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaler will only fit on training data so, calculates Mean & STD and stores this on the scaler\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols]) # Uses scaler that has only seen the traning data -> standardize \n",
    "\n",
    "# Combine transformed training group +  assigned clean, matching row indices\n",
    "df_train = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e016f21-ac07-47a9-b256-45adb87d1dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 2366 outliers from training data.\n"
     ]
    }
   ],
   "source": [
    "# Removing 'MentHlth' from being an outlier as a single unique value is being treated as an outlier but, is a valid data point\n",
    "numerical_cols2 = ['BMI', 'Age']\n",
    "\n",
    "# Set a z-score threshold: ±1 SD → ~68.3% of data, ±2 SD → ~95.5% of data, ±3 SD → ~99.7% of data\n",
    "threshold = 3    \n",
    "\n",
    "# Calculate absolute z-scores for numerical columns\n",
    "z_scores = np.abs(df_train[numerical_cols2])\n",
    "\n",
    "# Mask: rows where any numerical feature has a z-score >= threshold of 3\n",
    "outlier_mask = (z_scores >= threshold).any(axis=1)\n",
    "\n",
    "# Get the outlier rows\n",
    "outliers = df_train[outlier_mask]\n",
    "\n",
    "# Get the cleaned training data (rows that are NOT outliers)\n",
    "df_train_cleaned = df_train[~outlier_mask].reset_index(drop=True)\n",
    "\n",
    "# Show the outliers\n",
    "# print(\"Outlier rows removed from training data:\")\n",
    "# print(outliers)\n",
    "\n",
    "# Print how many were removed\n",
    "print(f\"\\nRemoved {len(outliers)} outliers from training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "949541b0-4a15-478a-989c-daa49412da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit scaler on cleaned training data\n",
    "scaler = StandardScaler()\n",
    "df_train_cleaned[numerical_cols] = scaler.fit_transform(df_train_cleaned[numerical_cols])\n",
    "\n",
    "# Apply same transformation to test data\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f4b707-e6df-49fa-a924-bef63529fff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.6.1 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.847     0.945     0.893     42795\n",
      "         1.0      0.026     0.082     0.039       944\n",
      "         2.0      0.000     0.000     0.000      6997\n",
      "\n",
      "    accuracy                          0.799     50736\n",
      "   macro avg      0.291     0.342     0.311     50736\n",
      "weighted avg      0.715     0.799     0.754     50736\n",
      "\n",
      "\n",
      "Threshold: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.849     0.922     0.884     42795\n",
      "         1.0      0.026     0.115     0.042       944\n",
      "         2.0      0.000     0.000     0.000      6997\n",
      "\n",
      "    accuracy                          0.780     50736\n",
      "   macro avg      0.292     0.346     0.309     50736\n",
      "weighted avg      0.716     0.780     0.746     50736\n",
      "\n",
      "\n",
      "Threshold: 0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.851     0.889     0.870     42795\n",
      "         1.0      0.025     0.161     0.043       944\n",
      "         2.0      0.000     0.000     0.000      6997\n",
      "\n",
      "    accuracy                          0.753     50736\n",
      "   macro avg      0.292     0.350     0.304     50736\n",
      "weighted avg      0.719     0.753     0.734     50736\n",
      "\n",
      "\n",
      "Threshold: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.855     0.831     0.843     42795\n",
      "         1.0      0.025     0.239     0.045       944\n",
      "         2.0      0.000     0.000     0.000      6997\n",
      "\n",
      "    accuracy                          0.706     50736\n",
      "   macro avg      0.293     0.357     0.296     50736\n",
      "weighted avg      0.722     0.706     0.712     50736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\willr\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"models/SVC_SMOTE_with_raw_data.joblib\")\n",
    "\n",
    "thresholds = [0.5, 0.4, 0.3, 0.2]\n",
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (probs > t).astype(int)\n",
    "    print(f\"\\nThreshold: {t}\")\n",
    "    print(classification_report(y_test, preds, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1391f9e-9d58-4f12-bbc7-de70862b3a35",
   "metadata": {},
   "source": [
    "- Plot Precision-Recall Curve- Use it to find the threshold that gives you the best balance:\n",
    "- This tells you how well your model handles the trade-offs and shows whether tuning the threshold actually has value — or if it’s all noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b7a28f-fb9e-4321-8491-3cd42d89b6f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_recall_curve\n\u001b[1;32m----> 3\u001b[0m prec, rec, thresh \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (prec \u001b[38;5;241m*\u001b[39m rec) \u001b[38;5;241m/\u001b[39m (prec \u001b[38;5;241m+\u001b[39m rec \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Find best F1 score threshold\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1002\u001b[0m, in \u001b[0;36mprecision_recall_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate, probas_pred)\u001b[0m\n\u001b[0;32m    993\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    994\u001b[0m         (\n\u001b[0;32m    995\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobas_pred was deprecated in version 1.5 and will be removed in 1.7.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    999\u001b[0m     )\n\u001b[0;32m   1000\u001b[0m     y_score \u001b[38;5;241m=\u001b[39m probas_pred\n\u001b[1;32m-> 1002\u001b[0m fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1007\u001b[0m     \u001b[38;5;66;03m# Drop thresholds corresponding to points where true positives (tps)\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;66;03m# do not change from the previous or subsequent point. This will keep\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;66;03m# only the first and last point for each tps value. All points\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# with the same tps value have the same recall and thus x coordinate.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;66;03m# They appear as a vertical line on the plot.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m     optimal_idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[0;32m   1013\u001b[0m         np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m   1014\u001b[0m             [[\u001b[38;5;28;01mTrue\u001b[39;00m], np\u001b[38;5;241m.\u001b[39mlogical_or(np\u001b[38;5;241m.\u001b[39mdiff(tps[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), np\u001b[38;5;241m.\u001b[39mdiff(tps[\u001b[38;5;241m1\u001b[39m:])), [\u001b[38;5;28;01mTrue\u001b[39;00m]]\n\u001b[0;32m   1015\u001b[0m         )\n\u001b[0;32m   1016\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\STU_stuff\\Data_An_631\\Final_Proj\\env\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:817\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    815\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m--> 817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m    819\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    820\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "prec, rec, thresh = precision_recall_curve(y_test, probs)\n",
    "f1 = 2 * (prec * rec) / (prec + rec + 1e-10)\n",
    "\n",
    "# Find best F1 score threshold\n",
    "best_idx = np.argmax(f1)\n",
    "best_threshold = thresh[best_idx]\n",
    "print(f\"Best threshold by F1: {best_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d9688d-e84c-41b9-af54-0ba26b9b59a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
