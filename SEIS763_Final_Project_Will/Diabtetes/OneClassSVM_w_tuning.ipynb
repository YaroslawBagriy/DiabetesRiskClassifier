{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090f8075-9d96-4f26-ab92-e6a523524832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "0     1.0       1.0        1.0  40.0     1.0     0.0                   0.0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  ...  AnyHealthcare  NoDocbcCost  GenHlth  \\\n",
       "0           0.0     0.0      1.0  ...            1.0          0.0      5.0   \n",
       "\n",
       "   MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  Income  \n",
       "0      18.0      15.0       1.0  0.0  9.0        4.0     3.0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, classification_report, roc_auc_score, log_loss\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "original_df = pd.read_csv('Data/diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "\n",
    "y = original_df.Diabetes_012\n",
    "X = original_df.drop('Diabetes_012', axis=1)\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6bae41-7937-468f-8f2a-06891552057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Predictors\n",
    "numerical_cols = ['BMI', 'MentHlth', 'PhysHlth', 'Age']\n",
    "# numerical_cols = list(dict.fromkeys(numerical_cols))  # Remove duplicates just in case\n",
    "\n",
    "# Categorical Predictors\n",
    "categorical_cols = [\n",
    "    'HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "    'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "    'NoDocbcCost', 'GenHlth', 'DiffWalk', 'Sex', 'Education', 'Income'\n",
    "]\n",
    "\n",
    "# One-hot encode categorical features and drop the first category of each\n",
    "# Feature Engineering - Turns categorical data into a numerical format that a model can understand\n",
    "X_cat = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Extract the numerical features\n",
    "X_num = X[numerical_cols]\n",
    "\n",
    "# Concatenate numerical and encoded categorical features\n",
    "X = pd.concat([X_num, X_cat], axis=1)\n",
    "\n",
    "# Remove any duplicated columns that may result from concat\n",
    "X = X.loc[:, ~X.columns.duplicated()]\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaler will only fit on training data so, calculates Mean & STD and stores this on the scaler\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols]) # Uses scaler that has only seen the traning data -> standardize \n",
    "\n",
    "# Combine transformed training group +  assigned clean, matching row indices\n",
    "df_train = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ead5d08-2a56-4c2b-918f-7e7ebb995aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 2366 outliers from training data.\n"
     ]
    }
   ],
   "source": [
    "# Removing 'MentHlth' from being an outlier as a single unique value is being treated as an outlier but, is a valid data point\n",
    "numerical_cols2 = ['BMI', 'Age']\n",
    "\n",
    "# Set a z-score threshold: ±1 SD → ~68.3% of data, ±2 SD → ~95.5% of data, ±3 SD → ~99.7% of data\n",
    "threshold = 3    \n",
    "\n",
    "# Calculate absolute z-scores for numerical columns\n",
    "z_scores = np.abs(df_train[numerical_cols2])\n",
    "\n",
    "# Mask: rows where any numerical feature has a z-score >= threshold of 3\n",
    "outlier_mask = (z_scores >= threshold).any(axis=1)\n",
    "\n",
    "# Get the outlier rows\n",
    "outliers = df_train[outlier_mask]\n",
    "\n",
    "# Get the cleaned training data (rows that are NOT outliers)\n",
    "df_train_cleaned = df_train[~outlier_mask].reset_index(drop=True)\n",
    "\n",
    "# Show the outliers\n",
    "# print(\"Outlier rows removed from training data:\")\n",
    "# print(outliers)\n",
    "\n",
    "# Print how many were removed\n",
    "print(f\"\\nRemoved {len(outliers)} outliers from training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646bff3c-4a58-4afd-bf8c-c3a4dbcd86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit scaler on cleaned training data\n",
    "scaler = StandardScaler()\n",
    "df_train_cleaned[numerical_cols] = scaler.fit_transform(df_train_cleaned[numerical_cols])\n",
    "\n",
    "# Apply same transformation to test data\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c58c5a40-a998-4da4-b9e6-c9fd417a332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set(X_test.columns) - set(df_train_cleaned.drop('Diabetes_012', axis=1).columns))\n",
    "print(set(df_train_cleaned.drop('Diabetes_012', axis=1).columns) - set(X_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd20231a-d660-4b95-ba0f-f91cd94c6d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data (features and labels) ===\n",
    "X_train = df_train_cleaned.drop('Diabetes_012', axis=1)\n",
    "y_train = df_train_cleaned.Diabetes_012  # or your actual target column\n",
    "\n",
    "# Reindex X_test to match final X_train\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd1d0ffe-b13f-4eca-b50b-f74f916dc0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training OneClassSVM models with nu = 0.01\n",
      "\n",
      "Training OneClassSVM models with nu = 0.1\n",
      "\n",
      "Training OneClassSVM models with nu = 0.3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "\n",
    "# Define nu values to try\n",
    "nu_values = [0.01, 0.1, 0.3]\n",
    "\n",
    "# Dictionary to hold models: models[nu][class] = OneClassSVM\n",
    "models_by_nu = {}\n",
    "\n",
    "for nu in nu_values:\n",
    "    print(f\"\\nTraining OneClassSVM models with nu = {nu}\")\n",
    "    models = {}\n",
    "\n",
    "    for cls in y_train.unique():\n",
    "        # Subset training data for the current class\n",
    "        X_cls = X_train[y_train == cls]\n",
    "\n",
    "        # Train OneClassSVM for this class and nu value\n",
    "        model = OneClassSVM(kernel='rbf', gamma='auto', nu=nu)\n",
    "        model.fit(X_cls)\n",
    "\n",
    "        models[cls] = model\n",
    "\n",
    "    # Store all models for this nu value\n",
    "    models_by_nu[nu] = models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1e5aa4-e5a1-4ad7-8f69-34091af6f687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring with nu = 0.01\n",
      "\n",
      "Scoring with nu = 0.1\n",
      "\n",
      "Scoring with nu = 0.3\n"
     ]
    }
   ],
   "source": [
    "# Store results\n",
    "scores_by_nu = {}\n",
    "\n",
    "for nu, models in models_by_nu.items():\n",
    "    print(f\"\\nScoring with nu = {nu}\")\n",
    "\n",
    "    # Compute decision function scores for each class\n",
    "    scores = {cls: model.decision_function(X_test) for cls, model in models.items()}\n",
    "\n",
    "    # Combine scores into matrix: (rows = samples, cols = classes)\n",
    "    X_test_scores = np.column_stack([scores[cls] for cls in sorted(models)])\n",
    "\n",
    "    # Predict class with highest score (most likely inlier)\n",
    "    y_pred = np.argmax(X_test_scores, axis=1)\n",
    "\n",
    "    # Store results\n",
    "    scores_by_nu[nu] = {\n",
    "        'scores': X_test_scores,\n",
    "        'y_pred': y_pred\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc2e3eaa-0be9-4ed7-9896-7104d8b0699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification Report for nu = 0.01 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.98      0.91     42795\n",
      "         1.0       0.03      0.02      0.02       944\n",
      "         2.0       0.47      0.03      0.05      6997\n",
      "\n",
      "    accuracy                           0.83     50736\n",
      "   macro avg       0.45      0.34      0.33     50736\n",
      "weighted avg       0.78      0.83      0.77     50736\n",
      "\n",
      "\n",
      "--- Classification Report for nu = 0.1 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.89      0.87     42795\n",
      "         1.0       0.02      0.09      0.03       944\n",
      "         2.0       0.39      0.13      0.19      6997\n",
      "\n",
      "    accuracy                           0.77     50736\n",
      "   macro avg       0.42      0.37      0.37     50736\n",
      "weighted avg       0.78      0.77      0.76     50736\n",
      "\n",
      "\n",
      "--- Classification Report for nu = 0.3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.68      0.77     42795\n",
      "         1.0       0.02      0.25      0.04       944\n",
      "         2.0       0.34      0.26      0.29      6997\n",
      "\n",
      "    accuracy                           0.62     50736\n",
      "   macro avg       0.42      0.40      0.37     50736\n",
      "weighted avg       0.79      0.62      0.69     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for nu in scores_by_nu:\n",
    "    print(f\"\\n--- Classification Report for nu = {nu} ---\")\n",
    "    y_pred = scores_by_nu[nu]['y_pred']\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfd5a7b-e0c5-4f8b-a7e0-2f97ce8473ce",
   "metadata": {},
   "source": [
    "My data is too big, can we use undersampling then, remove highly overlapping samples for class 2 (e.g., ones with lowest z-score distance from class 0 to build clearer margins helping SVM focus), train OneClassSVM boosting nu and gamma specifically for class 2, Use class-wise score thresholds instead of strict argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4a936b7-42ee-4188-b034-ffac3b0ce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Only use classes 0 and 1 for undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Combine X and y (excluding class 2)\n",
    "mask = y_train != 2\n",
    "X_temp, y_temp = rus.fit_resample(X_train[mask], y_train[mask])\n",
    "\n",
    "# Now add all of class 2 back in\n",
    "X_balanced = pd.concat([X_temp, X_train[y_train == 2]], axis=0)\n",
    "y_balanced = pd.concat([y_temp, y_train[y_train == 2]], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "474f139b-ddee-4acb-ad06-fae6033c51f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For class 2, remove overlapping samples using z-score distance from class 0 mean\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Get means for class 0\n",
    "X0 = X_balanced[y_balanced == 0]\n",
    "X2 = X_balanced[y_balanced == 2]\n",
    "\n",
    "# Compute z-scores (distance from class 0 mean)\n",
    "z_scores = np.abs((X2 - X0.mean()) / X0.std())\n",
    "\n",
    "# Keep only top X% furthest points (e.g., top 70%)\n",
    "X2 = X2.copy()  \n",
    "X2.loc[:, 'z_dist'] = z_scores.mean(axis=1)\n",
    "X2_filtered = X2.sort_values(by='z_dist', ascending=False).drop('z_dist', axis=1)\n",
    "X2_filtered = X2_filtered.iloc[:int(len(X2_filtered) * 0.7)]  # top 70% most distinct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27f661c4-253a-4b9a-b381-c9897d89bf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.15      0.26     42795\n",
      "         1.0       0.01      0.24      0.02       944\n",
      "         2.0       0.18      0.66      0.29      6997\n",
      "\n",
      "    accuracy                           0.22     50736\n",
      "   macro avg       0.35      0.35      0.19     50736\n",
      "weighted avg       0.75      0.22      0.26     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = OneClassSVM(kernel='rbf', gamma='scale', nu=0.4)\n",
    "model_2.fit(X2_filtered)\n",
    "\n",
    "# Train OneClassSVM for class 0\n",
    "X0 = X_balanced[y_balanced == 0]\n",
    "model_0 = OneClassSVM(kernel='rbf', gamma='scale', nu=0.01)\n",
    "model_0.fit(X0)\n",
    "\n",
    "# Train OneClassSVM for class 1\n",
    "X1 = X_balanced[y_balanced == 1]\n",
    "model_1 = OneClassSVM(kernel='rbf', gamma='scale', nu=0.1)\n",
    "model_1.fit(X1)\n",
    "\n",
    "# Get decision scores per class\n",
    "scores = {\n",
    "    0: model_0.decision_function(X_test),\n",
    "    1: model_1.decision_function(X_test),\n",
    "    2: model_2.decision_function(X_test)\n",
    "}\n",
    "\n",
    "# Apply a class-wise score threshold boost (favor class 2)\n",
    "scores[2] += 0.2  # adjust this to tune recall vs precision\n",
    "\n",
    "# Stack and predict class with highest adjusted score\n",
    "score_matrix = np.column_stack([scores[cls] for cls in sorted(scores)])\n",
    "y_pred = np.argmax(score_matrix, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03ec3ef8-07b0-4ba9-9dea-6c1bf6e025df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.15      0.26     42795\n",
      "         1.0       0.01      0.24      0.02       944\n",
      "         2.0       0.18      0.66      0.29      6997\n",
      "\n",
      "    accuracy                           0.22     50736\n",
      "   macro avg       0.35      0.35      0.19     50736\n",
      "weighted avg       0.75      0.22      0.26     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Post-predict filter:\n",
    "# This compares actual class 2 score to the best of class 0 or 1\n",
    "# It only keeps class 2 predictions when they are meaningfully stronger\n",
    "# This lets you keep strong class 2 predictions, while rejecting borderline false positives → precision improves.\n",
    "\n",
    "# Step 1: Stack score matrix\n",
    "score_matrix = np.column_stack([scores[cls] for cls in sorted(scores)])\n",
    "y_pred = np.argmax(score_matrix, axis=1)\n",
    "\n",
    "# Step 2: Filter weak class 2 predictions\n",
    "for i, pred in enumerate(y_pred):\n",
    "    if pred == 2:\n",
    "        second_best = max(score_matrix[i, 0], score_matrix[i, 1])\n",
    "        margin = score_matrix[i, 2] - second_best\n",
    "        if margin < 0.2:  # tweak this value\n",
    "            y_pred[i] = np.argmax(score_matrix[i, :2])  # fallback to class 0 or 1\n",
    "\n",
    "# Step 5: Evaluate results\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c07f74cf-50b6-4b6d-b2a4-e94d2087b505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.15      0.26     42795\n",
      "         1.0       0.01      0.44      0.03       944\n",
      "         2.0       0.31      0.53      0.39      6997\n",
      "\n",
      "    accuracy                           0.21     50736\n",
      "   macro avg       0.39      0.37      0.23     50736\n",
      "weighted avg       0.76      0.21      0.27     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hybrid: Train binary classifier for class 2 vs rest (only for refining predictions)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Binary classifier for class 2 (vs. all others)\n",
    "y_binary = (y_train == 2).astype(int)\n",
    "clf_bin = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "clf_bin.fit(X_train, y_binary)\n",
    "\n",
    "# OneClassSVM predictions\n",
    "y_pred = np.argmax(score_matrix, axis=1)\n",
    "\n",
    "# Filter borderline class 2s using classifier\n",
    "for i, pred in enumerate(y_pred):\n",
    "    if pred == 2:\n",
    "        proba = clf_bin.predict_proba(X_test.iloc[[i]])[0][1]  \n",
    "        if proba < 0.5:  # You can tune this threshold\n",
    "            y_pred[i] = np.argmax(score_matrix[i, :2])\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792376e-4e57-4baf-a8ae-9e34c1bc504d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
