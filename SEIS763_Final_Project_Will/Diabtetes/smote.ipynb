{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cbdf028-2c57-4fcc-86d9-a5a55647ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, classification_report, roc_auc_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67234485-c2d6-4cdf-adae-219c78614378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for the values of for the target variable\n",
      "\n",
      "Diabetes_012\n",
      "0.0    213703\n",
      "2.0     35346\n",
      "1.0      4631\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "original_df = pd.read_csv('Data/diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "\n",
    "print('Distribution for the values of for the target variable\\n')\n",
    "print(original_df[\"Diabetes_012\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c3e2ef-964c-4b24-bc5b-b7900242ca52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "0     1.0       1.0        1.0  40.0     1.0     0.0                   0.0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  ...  AnyHealthcare  NoDocbcCost  GenHlth  \\\n",
       "0           0.0     0.0      1.0  ...            1.0          0.0      5.0   \n",
       "\n",
       "   MentHlth  PhysHlth  DiffWalk  Sex  Age  Education  Income  \n",
       "0      18.0      15.0       1.0  0.0  9.0        4.0     3.0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = original_df.Diabetes_012\n",
    "X = original_df.drop('Diabetes_012', axis=1)\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef95ec68-639a-4d80-a56f-33ffef9d034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Predictors\n",
    "numerical_cols = ['BMI', 'MentHlth', 'PhysHlth', 'Age']\n",
    "# numerical_cols = list(dict.fromkeys(numerical_cols))  # Remove duplicates just in case\n",
    "\n",
    "# Categorical Predictors\n",
    "categorical_cols = [\n",
    "    'HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "    'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare',\n",
    "    'NoDocbcCost', 'GenHlth', 'DiffWalk', 'Sex', 'Education', 'Income'\n",
    "]\n",
    "\n",
    "# One-hot encode categorical features and drop the first category of each\n",
    "X_cat = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Extract the numerical features\n",
    "X_num = X[numerical_cols]\n",
    "\n",
    "# Concatenate numerical and encoded categorical features\n",
    "X = pd.concat([X_num, X_cat], axis=1)\n",
    "\n",
    "# Remove any duplicated columns that may result from concat\n",
    "X = X.loc[:, ~X.columns.duplicated()]\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaler will only fit on training data so, calculates Mean & STD and stores this on the scaler\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols]) # Uses scaler that has only seen the traning data -> standardize \n",
    "\n",
    "# Combine transformed training group +  assigned clean, matching row indices\n",
    "df_train = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423c5a3e-35b9-4be6-afb7-bec639cb226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 2366 outliers from training data.\n"
     ]
    }
   ],
   "source": [
    "# Removing 'MentHlth' from being an outlier as a single unique value is being treated as an outlier but, is a valid data point\n",
    "numerical_cols2 = ['BMI', 'PhysHlth', 'Age']\n",
    "\n",
    "# Set a z-score threshold: ±1 SD → ~68.3% of data, ±2 SD → ~95.5% of data, ±3 SD → ~99.7% of data\n",
    "threshold = 3    \n",
    "\n",
    "# Calculate absolute z-scores for numerical columns\n",
    "z_scores = np.abs(df_train[numerical_cols2])\n",
    "\n",
    "# Mask: rows where any numerical feature has a z-score >= threshold of 3\n",
    "outlier_mask = (z_scores >= threshold).any(axis=1)\n",
    "\n",
    "# Get the outlier rows\n",
    "outliers = df_train[outlier_mask]\n",
    "\n",
    "# Get the cleaned training data (rows that are NOT outliers)\n",
    "df_train_cleaned = df_train[~outlier_mask].reset_index(drop=True)\n",
    "\n",
    "# Show the outliers\n",
    "# print(\"Outlier rows removed from training data:\")\n",
    "# print(outliers)\n",
    "\n",
    "# Print how many were removed\n",
    "print(f\"\\nRemoved {len(outliers)} outliers from training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5830bd6d-d486-492c-a7e6-e4e9539c3905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Standardized Training Data:\n",
      "                BMI      MentHlth      PhysHlth           Age\n",
      "count  2.029440e+05  2.029440e+05  2.029440e+05  2.029440e+05\n",
      "mean   2.687503e-16  4.513016e-17 -7.142400e-18 -1.776497e-16\n",
      "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00\n",
      "min   -2.475946e+00 -4.299017e-01 -4.871967e-01 -2.303520e+00\n",
      "25%   -6.611649e-01 -4.299017e-01 -4.871967e-01 -6.658286e-01\n",
      "50%   -2.074697e-01 -4.299017e-01 -4.871967e-01 -1.075203e-02\n",
      "75%    3.974572e-01 -1.606003e-01 -1.431950e-01  6.443245e-01\n",
      "max    1.052998e+01  3.609619e+00  2.952820e+00  1.626939e+00\n",
      "\n",
      "Cleaned + Re-standardized Training Data:\n",
      "                BMI      MentHlth      PhysHlth           Age\n",
      "count  2.005780e+05  2.005780e+05  2.005780e+05  2.005780e+05\n",
      "mean   8.785340e-18 -9.201581e-17  2.897745e-17 -3.276790e-17\n",
      "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00\n",
      "min   -2.855967e+00 -4.273583e-01 -4.833907e-01 -2.305616e+00\n",
      "25%   -7.155151e-01 -4.273583e-01 -4.833907e-01 -6.692564e-01\n",
      "50%   -1.804021e-01 -4.273583e-01 -4.833907e-01 -1.471254e-02\n",
      "75%    5.330819e-01 -1.563030e-01 -1.367568e-01  6.398313e-01\n",
      "max    3.565389e+00  3.638472e+00  2.982948e+00  1.621647e+00\n"
     ]
    }
   ],
   "source": [
    "# Refit scaler on cleaned training data\n",
    "scaler = StandardScaler()\n",
    "df_train_cleaned[numerical_cols] = scaler.fit_transform(df_train_cleaned[numerical_cols])\n",
    "\n",
    "# Apply same transformation to test data\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# Summary of the original standardized training data (before outlier removal)\n",
    "print(\"Original Standardized Training Data:\")\n",
    "print(df_train[numerical_cols].describe())\n",
    "\n",
    "# Summary of the re-standardized, cleaned training data\n",
    "print(\"\\nCleaned + Re-standardized Training Data:\")\n",
    "print(df_train_cleaned[numerical_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22b28f69-23d5-4e28-b5a4-34974d01aee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE oversampling: Counter({0.0: 169449, 2.0: 27521, 1.0: 3608})\n",
      "After SMOTE oversampling: Counter({0.0: 169449, 2.0: 169449, 1.0: 169449})\n",
      "After SMOTE on raw (no outlier removal): Counter({0.0: 170908, 2.0: 170908, 1.0: 170908})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Use the cleaned dataset (after removing outliers)\n",
    "X_train_smote = df_train_cleaned.drop('Diabetes_012', axis=1)\n",
    "y_train_smote = df_train_cleaned['Diabetes_012']\n",
    "\n",
    "# Check original class distribution\n",
    "print(\"Before SMOTE oversampling:\", Counter(y_train_smote))\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train_smote, y_train_smote)\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "print(\"After SMOTE oversampling:\", Counter(y_smote))\n",
    "\n",
    "# Optional: Also apply SMOTE to raw data (no outlier removal)\n",
    "X_train_smote_raw = df_train.drop('Diabetes_012', axis=1)\n",
    "y_train_smote_raw = df_train['Diabetes_012']\n",
    "\n",
    "smote_raw = SMOTE(random_state=42)\n",
    "X_smote_raw, y_smote_raw = smote_raw.fit_resample(X_train_smote_raw, y_train_smote_raw)\n",
    "\n",
    "print(\"After SMOTE on raw (no outlier removal):\", Counter(y_smote_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c02ffb4d-2fc9-4f47-a23c-16fffd5454e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "models = {\n",
    "    'SVC': SVC(probability=True, class_weight='balanced', random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'OneVsRest_LogRegCV': OneVsRestClassifier(\n",
    "        LogisticRegressionCV(\n",
    "            class_weight='balanced',\n",
    "            cv=3,\n",
    "            max_iter=200,\n",
    "            penalty='l1',\n",
    "            random_state=42,\n",
    "            scoring='roc_auc',\n",
    "            solver='liblinear'\n",
    "        )\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3263748-8aa6-4c7c-8de1-f3d378281765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X_train, y_train, X_test, y_test, label=\"\"):\n",
    "    \"\"\"\n",
    "    Trains, evaluates, and saves multiple classification models.\n",
    "    Prints accuracy, classification report, and confusion matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - models: dict of model name → model object\n",
    "    - X_train, y_train: training features and labels\n",
    "    - X_test, y_test: test features and labels\n",
    "    - label: string label to tag the evaluation (e.g., 'SMOTE_cleaned')\n",
    "    \"\"\"\n",
    "    # Create a directory to store models\n",
    "    save_dir = f\"saved_models/{label.replace(' ', '_')}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n🔹 Model: {name} ({label})\")\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Save the model\n",
    "        filename = os.path.join(save_dir, f\"{name}_{label.replace(' ', '_')}.joblib\")\n",
    "        joblib.dump(model, filename)\n",
    "        print(f\"Saved model to: {filename}\")\n",
    "\n",
    "        # Evaluate\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        cm_df = pd.DataFrame(cm, index=[f'Actual {i}' for i in np.unique(y_test)],\n",
    "                                columns=[f'Predicted {i}' for i in np.unique(y_test)])\n",
    "        print(\"\\nConfusion Matrix:\\n\", cm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b42616c5-d274-4073-9dd8-2aa690c191f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Model: SVC (SMOTE with cleaned data)\n",
      "Saved model to: saved_models/SMOTE_with_cleaned_data\\SVC_SMOTE_with_cleaned_data.joblib\n",
      "Accuracy: 0.7096\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.74      0.82     42795\n",
      "         1.0       0.03      0.12      0.04       944\n",
      "         2.0       0.34      0.60      0.43      6997\n",
      "\n",
      "    accuracy                           0.71     50736\n",
      "   macro avg       0.43      0.48      0.43     50736\n",
      "weighted avg       0.83      0.71      0.76     50736\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "             Predicted 0.0  Predicted 1.0  Predicted 2.0\n",
      "Actual 0.0          31717           3356           7722\n",
      "Actual 1.0            415            110            419\n",
      "Actual 2.0           2002            821           4174\n",
      "\n",
      "🔹 Model: RandomForest (SMOTE with cleaned data)\n",
      "Saved model to: saved_models/SMOTE_with_cleaned_data\\RandomForest_SMOTE_with_cleaned_data.joblib\n",
      "Accuracy: 0.8086\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89     42795\n",
      "         1.0       0.02      0.01      0.01       944\n",
      "         2.0       0.38      0.42      0.40      6997\n",
      "\n",
      "    accuracy                           0.81     50736\n",
      "   macro avg       0.43      0.44      0.44     50736\n",
      "weighted avg       0.81      0.81      0.81     50736\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "             Predicted 0.0  Predicted 1.0  Predicted 2.0\n",
      "Actual 0.0          38047            262           4486\n",
      "Actual 1.0            662              8            274\n",
      "Actual 2.0           3934             94           2969\n",
      "\n",
      "🔹 Model: GradientBoosting (SMOTE with cleaned data)\n",
      "Saved model to: saved_models/SMOTE_with_cleaned_data\\GradientBoosting_SMOTE_with_cleaned_data.joblib\n",
      "Accuracy: 0.7873\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.84      0.88     42795\n",
      "         1.0       0.04      0.07      0.05       944\n",
      "         2.0       0.39      0.54      0.46      6997\n",
      "\n",
      "    accuracy                           0.79     50736\n",
      "   macro avg       0.45      0.48      0.46     50736\n",
      "weighted avg       0.83      0.79      0.80     50736\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "             Predicted 0.0  Predicted 1.0  Predicted 2.0\n",
      "Actual 0.0          36093           1220           5482\n",
      "Actual 1.0            543             62            339\n",
      "Actual 2.0           2801            409           3787\n",
      "\n",
      "🔹 Model: OneVsRest_LogRegCV (SMOTE with cleaned data)\n",
      "Saved model to: saved_models/SMOTE_with_cleaned_data\\OneVsRest_LogRegCV_SMOTE_with_cleaned_data.joblib\n",
      "Accuracy: 0.7160\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.75      0.83     42795\n",
      "         1.0       0.03      0.14      0.05       944\n",
      "         2.0       0.36      0.58      0.44      6997\n",
      "\n",
      "    accuracy                           0.72     50736\n",
      "   macro avg       0.44      0.49      0.44     50736\n",
      "weighted avg       0.83      0.72      0.76     50736\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "             Predicted 0.0  Predicted 1.0  Predicted 2.0\n",
      "Actual 0.0          32139           3739           6917\n",
      "Actual 1.0            432            136            376\n",
      "Actual 2.0           2126            818           4053\n",
      "\n",
      "🔹 Model: SVC (SMOTE with raw data)\n",
      "Saved model to: saved_models/SMOTE_with_raw_data\\SVC_SMOTE_with_raw_data.joblib\n",
      "Accuracy: 0.7103\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.74      0.82     42795\n",
      "         1.0       0.03      0.13      0.05       944\n",
      "         2.0       0.34      0.60      0.44      6997\n",
      "\n",
      "    accuracy                           0.71     50736\n",
      "   macro avg       0.43      0.49      0.44     50736\n",
      "weighted avg       0.83      0.71      0.76     50736\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "             Predicted 0.0  Predicted 1.0  Predicted 2.0\n",
      "Actual 0.0          31696           3430           7669\n",
      "Actual 1.0            403            122            419\n",
      "Actual 2.0           1948            829           4220\n",
      "\n",
      "🔹 Model: RandomForest (SMOTE with raw data)\n",
      "Saved model to: saved_models/SMOTE_with_raw_data\\RandomForest_SMOTE_with_raw_data.joblib\n",
      "Accuracy: 0.3866\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.32      0.48     42795\n",
      "         1.0       0.01      0.11      0.02       944\n",
      "         2.0       0.20      0.81      0.32      6997\n",
      "\n",
      "    accuracy                           0.39     50736\n",
      "   macro avg       0.38      0.41      0.27     50736\n",
      "weighted avg       0.81      0.39      0.45     50736\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "             Predicted 0.0  Predicted 1.0  Predicted 2.0\n",
      "Actual 0.0          13876           6738          22181\n",
      "Actual 1.0            205            100            639\n",
      "Actual 2.0            966            393           5638\n",
      "\n",
      "🔹 Model: GradientBoosting (SMOTE with raw data)\n",
      "Saved model to: saved_models/SMOTE_with_raw_data\\GradientBoosting_SMOTE_with_raw_data.joblib\n",
      "Accuracy: 0.2339\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.17      0.29     42795\n",
      "         1.0       0.02      0.57      0.03       944\n",
      "         2.0       0.34      0.57      0.42      6997\n",
      "\n",
      "    accuracy                           0.23     50736\n",
      "   macro avg       0.44      0.44      0.25     50736\n",
      "weighted avg       0.87      0.23      0.31     50736\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "             Predicted 0.0  Predicted 1.0  Predicted 2.0\n",
      "Actual 0.0           7336          27977           7482\n",
      "Actual 1.0             39            534            371\n",
      "Actual 2.0            129           2871           3997\n",
      "\n",
      "🔹 Model: OneVsRest_LogRegCV (SMOTE with raw data)\n",
      "Saved model to: saved_models/SMOTE_with_raw_data\\OneVsRest_LogRegCV_SMOTE_with_raw_data.joblib\n",
      "Accuracy: 0.7132\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.75      0.83     42795\n",
      "         1.0       0.03      0.15      0.05       944\n",
      "         2.0       0.36      0.58      0.44      6997\n",
      "\n",
      "    accuracy                           0.71     50736\n",
      "   macro avg       0.44      0.49      0.44     50736\n",
      "weighted avg       0.83      0.71      0.76     50736\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "             Predicted 0.0  Predicted 1.0  Predicted 2.0\n",
      "Actual 0.0          31955           3802           7038\n",
      "Actual 1.0            422            137            385\n",
      "Actual 2.0           2088            818           4091\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using outlier-removed training data\n",
    "evaluate_models(models, X_smote, y_smote, X_test, y_test, label=\"SMOTE with cleaned data\")\n",
    "\n",
    "# Evaluate using outlier-inclusive training data\n",
    "evaluate_models(models, X_smote_raw, y_smote_raw, X_test, y_test, label=\"SMOTE with raw data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "457bf81b-29de-4cd1-b0d5-bc4aebc83fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_models(models, X_train, y_train, X_test, y_test, label=\"\"):\n",
    "#     \"\"\"\n",
    "#     Trains and evaluates a dictionary of classification models.\n",
    "\n",
    "#     For each model, it prints the accuracy, classification report, and a labeled confusion matrix\n",
    "#     using the provided training and test datasets. \n",
    "    \n",
    "#     Parameters:\n",
    "#     - models: dict of model name → model object\n",
    "#     - X_train, y_train: training features and labels\n",
    "#     - X_test, y_test: test features and labels\n",
    "#     - label: optional string to tag the evaluation (e.g., 'with outliers', 'without outliers')\n",
    "#     \"\"\"\n",
    "#     for name, model in models.items():\n",
    "#         print(f\"\\n🔹 Model: {name} ({label})\")\n",
    "\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "\n",
    "#         acc = accuracy_score(y_test, y_pred)\n",
    "#         print(f\"Accuracy: {acc:.4f}\")\n",
    "#         print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#         cm = confusion_matrix(y_test, y_pred)\n",
    "#         cm_df = pd.DataFrame(cm, index=[f'Actual {i}' for i in np.unique(y_test)],\n",
    "#                                 columns=[f'Predicted {i}' for i in np.unique(y_test)])\n",
    "#         print(\"\\nConfusion Matrix:\\n\", cm_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
